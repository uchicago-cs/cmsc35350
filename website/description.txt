The human brain consumes around 20 watts—less energy than a lightbulb—but can perform tasks, such as understanding natural language and interpreting images, that tax megawatt-scale supercomputers. Thus, we may wonder: can we achieve energy efficiencies similar to those of the human brain by building analog electronic circuits that mimic the neuro-biological architectures found in animal nervous systems? This concept, named neuromorphic computing, has become increasingly popular as the energy demands of conventional computers increase. Research in this area is producing a great variety of new computational architectures, microelectronics concepts, algorithmic approaches, and even neuroscience insights.

Our goal in this course is to introduce students to the state of knowledge in neuromorphic computing and thus to prepare them to undertake original research in this area. The class will be organized primarily around reading, presenting, and discussing research papers. Topics to be covered include:

* Neuromorphic concepts
* Theory and algorithms
* Microelectronics and devices
* Programming models and environments
* Applications: Machine learning, deep learning, robot control, ...
* Platforms: BrainScaleS, Loihi, SpiNNaker
* Neuroscience
